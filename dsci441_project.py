# -*- coding: utf-8 -*-
"""DSCI441_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hQrX4zq9cYPEuP9WmDAkrXfONMvxWNI6

ZHVI dataset comes from https://www.kaggle.com/datasets/paultimothymooney/zillow-house-price-data?select=Sale_Prices_City.csv

Unemployment rate dataset comes from https://www.kaggle.com/datasets/axeltorbenson/unemployment-data-19482021

Inflation Rate(CPI) Dataset https://www.kaggle.com/datasets/varpit94/us-inflation-data-updated-till-may-2021

Interest rate dataset https://www.kaggle.com/datasets/raoofiali/us-interest-rate-weekly

GDP Growth Rate dataset https://www.kaggle.com/datasets/rajkumarpandey02/economy-of-the-united-states
"""

#!pip install ydata-profiling
#!pip install tensorflow

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
import kagglehub
import math
import os
import warnings

#from ydata_profiling import ProfileReport
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge
from sklearn.linear_model import Lasso
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error, r2_score

from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.preprocessing import StandardScaler
#from tensorflow.keras.models import Sequential
#from tensorflow.keras.layers import Dense
from IPython.display import clear_output, display, HTML

warnings.filterwarnings("ignore")
clear_output()

"""Adding Housing Data"""

# Download housing data
path = kagglehub.dataset_download("paultimothymooney/zillow-house-price-data")

print("Files in the dataset:")
for root, dirs, files in os.walk(path):
    for file in files:
        print(os.path.join(root, file))

csv_path = os.path.join(path, "City_Zhvi_AllHomes.csv")
df = pd.read_csv(csv_path)
print(df.head())

# remove rows with NaN
df_cleaned = df.dropna()
print("DataFrame after removing rows with any NaN values:")
print(df_cleaned.head())
data = df_cleaned

# Remove location identifier since only one city has data for each month/year
data.drop('State',axis=1,inplace=True)
data.drop('CountyName',axis=1,inplace=True)
data.drop('SizeRank',axis=1,inplace=True)
data.drop('Metro',axis=1,inplace=True)
data.drop('Unnamed: 0',axis=1,inplace=True)
data.drop('RegionID',axis=1,inplace=True)
data.drop('RegionType',axis=1,inplace=True)
data.drop('StateName',axis=1,inplace=True)
data = data.reset_index(drop=True)

# Select single city (New York)
data = data[data['RegionName']=='New York']
data.drop('RegionName',axis=1,inplace=True)
print(data)

"""Adding Interest Rate Data"""

path = kagglehub.dataset_download("raoofiali/us-interest-rate-weekly")

print("Files in the dataset:")
for root, dirs, files in os.walk(path):
    for file in files:
        print(os.path.join(root, file))

xlsx_path = os.path.join(path, "Us-Interest Rate-Weekly.xlsx")
ir_df = pd.read_excel(xlsx_path)
ir_df.drop('Unnamed: 0',axis=1,inplace=True)
print(ir_df.head())
print(ir_df.tail())

# convert date format
ir_df['Date'] = pd.to_datetime(ir_df['Date'])

# Filter to include only rows between January 1996 and March 2020 to match housing data
start_date = pd.to_datetime('1996-01-01')
end_date = pd.to_datetime('2020-03-31')
filtered_ir_df = ir_df[(ir_df['Date'] >= start_date) & (ir_df['Date'] <= end_date)]

# Resample the data to get the monthly average
ir_df = filtered_ir_df.resample('M', on='Date').mean().reset_index()

# create time index
ir_df['Year'] = ir_df['Date'].dt.year
ir_df['Month'] = ir_df['Date'].dt.month
ir_df['TimeIndex'] = (ir_df['Year'] - ir_df['Year'].min()) * 12 + (ir_df['Month'] - ir_df['Month'].min())
ir_df.drop('Date',axis=1,inplace=True)

print(ir_df.head())
print(ir_df.tail())

"""Adding Inflation Rate Data"""

path = kagglehub.dataset_download("varpit94/us-inflation-data-updated-till-may-2021")

print("Files in the dataset:")
for root, dirs, files in os.walk(path):
    for file in files:
        print(os.path.join(root, file))

csv_path = os.path.join(path, "US CPI.csv")
cpi_df = pd.read_csv(csv_path)

print(cpi_df.head())
print(cpi_df.tail())

cpi_df['Yearmon'] = pd.to_datetime(cpi_df['Yearmon'], format='%d-%m-%Y')

start_date = pd.to_datetime('1996-01-01')
end_date = pd.to_datetime('2020-03-31')
filtered_cpi_df = cpi_df[(cpi_df['Yearmon'] >= start_date) & (cpi_df['Yearmon'] <= end_date)]
filtered_cpi_df = filtered_cpi_df.reset_index(drop=True)

filtered_cpi_df['Year'] = filtered_cpi_df['Yearmon'].dt.year
filtered_cpi_df['Month'] = filtered_cpi_df['Yearmon'].dt.month
filtered_cpi_df['TimeIndex'] = (filtered_cpi_df['Year'] - filtered_cpi_df['Year'].min()) * 12 + (filtered_cpi_df['Month'] - filtered_cpi_df['Month'].min())
filtered_cpi_df = filtered_cpi_df.reset_index(drop=True)

print(filtered_cpi_df)

"""Adding Unemployment rate data"""

# download unemployment rate data
path = kagglehub.dataset_download("axeltorbenson/unemployment-data-19482021")

print("Files in the dataset:")
for root, dirs, files in os.walk(path):
    for file in files:
        print(os.path.join(root, file))

# Load CSV file
csv_path = os.path.join(path, "unemployment_rate_data.csv")
un_df = pd.read_csv(csv_path)

print(un_df.head())
print(un_df.tail())

# select same range of dates of housing data and only the overall unemployment rate
un_df = un_df.iloc[576:576+291][['unrate','date']]
un_df = un_df.reset_index(drop=True)

# Convert the date column to get specific year and month feature
un_df['date'] = pd.to_datetime(un_df['date'])
un_df['Year'] = un_df['date'].dt.year
un_df['Month'] = un_df['date'].dt.month
un_df['TimeIndex'] = (un_df['Year'] - un_df['Year'].min()) * 12 + (un_df['Month'] - un_df['Month'].min())
un_df.drop('date',axis=1,inplace=True)

"""Adding GDP Growth %"""

# Download data
path = kagglehub.dataset_download("rajkumarpandey02/economy-of-the-united-states")

print("Path to dataset files:", path)

print("Files in the dataset:")
for root, dirs, files in os.walk(path):
    for file in files:
        print(os.path.join(root, file))

csv_path = os.path.join(path, "Economy of the United States.csv")
gdp_df = pd.read_csv(csv_path)

print(gdp_df.head())
print(gdp_df.tail())

gdp_df = gdp_df[gdp_df['Year'] >= 1996]
gdp_df = gdp_df[gdp_df['Year'] <= 2020]
gdp_df = gdp_df.reset_index(drop=True)
gdp_df = gdp_df[['Year','GDP growth (real)']]

gdp_df['GDP growth (real)'] = gdp_df['GDP growth (real)'].str.replace('%', '')
gdp_df['GDP Growth'] = pd.to_numeric(gdp_df['GDP growth (real)'])
gdp_df.drop('GDP growth (real)',axis=1,inplace=True)

# add instance for each month
gdp_df = gdp_df.loc[gdp_df.index.repeat(12)].reset_index(drop=True)
gdp_df['Month'] = (gdp_df.groupby('Year').cumcount() % 12) + 1
gdp_df = gdp_df.iloc[:-9]

print(gdp_df.head())
print(gdp_df.tail())

# reshape data to have rows correspond to each time, with features being the time, price, and unemployment rate
reshaped_data = []

# Loop through each column to get feature dates
for column in data.columns:
  year, month,day = map(int, column.split('-'))

  # Loop through each row to get price for the current date
  for index, row in data.iterrows():
   zhvi = row[column]

   reshaped_data.append({
      'ZHVI': zhvi,
      'Year': year,
      'Month': month,
      'Year-Month': f'{year}-{month}'
      })

reshaped_df = pd.DataFrame(reshaped_data)

# Add a time index
reshaped_df['TimeIndex'] = (reshaped_df['Year'] - reshaped_df['Year'].min()) * 12 + (reshaped_df['Month'] - reshaped_df['Month'].min())

# Sort data by month/year
full_df = reshaped_df.sort_values(by=['Year', 'Month']).reset_index(drop=True)
full_df['Unemployment Rate'] = un_df['unrate']
full_df['CPI'] = filtered_cpi_df['CPI']
full_df['Interest Rate'] = ir_df['Value']
full_df['GDP Growth'] = gdp_df['GDP Growth']
print("Reshaped DataFrame:")
print(full_df)

# Create figure and primary axis
fig, ax1 = plt.subplots(figsize=(18, 6))

# Plot the first ZHVI dataset
ax1.plot(full_df['Year-Month'], full_df['ZHVI'], color='blue', label='ZHVI')
ax1.set_xlabel('DATE')
ax1.set_ylabel('ZHVI', color='blue')
ax1.tick_params(axis='y', labelcolor='blue')

# Create a second axis sharing the same x-axis
ax2 = ax1.twinx()

# Plot the Unemployment Rate data
ax2.plot(un_df['TimeIndex'], un_df['unrate'], color='red', label='Unemployment Rate')
ax2.set_ylabel('Unemployment Rate', color='red')
ax2.tick_params(axis='y', labelcolor='red')

x_ticks = np.arange(0, 290, 24)
ax1.set_xticks(x_ticks)

plt.title('Time Series Plot of ZHVI and Unemployment Rate Over Time')

# legend
ax1.legend(loc='upper left')
ax2.legend(loc='upper right')

plt.show()

# Create figure and primary axis
fig, ax1 = plt.subplots(figsize=(18, 6))

# Plot the first ZHVI dataset
ax1.plot(full_df['Year-Month'], full_df['ZHVI'], color='blue', label='ZHVI')
ax1.set_xlabel('DATE')
ax1.set_ylabel('ZHVI', color='blue')
ax1.tick_params(axis='y', labelcolor='blue')

# Create a second axis sharing the same x-axis
ax2 = ax1.twinx()

# Plot the Unemployment Rate data
ax2.plot(filtered_cpi_df['TimeIndex'], filtered_cpi_df['CPI'], color='red', label='CPI')
ax2.set_ylabel('CPI', color='red')
ax2.tick_params(axis='y', labelcolor='red')

x_ticks = np.arange(0, 290, 24)
ax1.set_xticks(x_ticks)

plt.title('Time Series Plot of ZHVI and CPI Over Time')

# legend
ax1.legend(loc='upper left')
ax2.legend(loc='upper right')

plt.show()

# Create figure and primary axis
fig, ax1 = plt.subplots(figsize=(18, 6))

# Plot the first ZHVI dataset
ax1.plot(full_df['Year-Month'], full_df['ZHVI'], color='blue', label='ZHVI')
ax1.set_xlabel('DATE')
ax1.set_ylabel('ZVHI', color='blue')
ax1.tick_params(axis='y', labelcolor='blue')

# Create a second axis sharing the same x-axis
ax2 = ax1.twinx()

# Plot the Unemployment Rate data
ax2.plot(ir_df['TimeIndex'], ir_df['Value'], color='red', label='Interest Rate')
ax2.set_ylabel('Interest Rate', color='red')
ax2.tick_params(axis='y', labelcolor='red')

x_ticks = np.arange(0, 290, 24)
ax1.set_xticks(x_ticks)

plt.title('Time Series Plot of ZHVI and Interest Rate Over Time')

# legend
ax1.legend(loc='upper left')
ax2.legend(loc='upper right')

plt.show()

# Create figure and primary axis
fig, ax1 = plt.subplots(figsize=(18, 6))

# Plot the first ZHVI dataset
ax1.plot(full_df['Year-Month'], full_df['ZHVI'], color='blue', label='ZHVI')
ax1.set_xlabel('DATE')
ax1.set_ylabel('ZHVI', color='blue')
ax1.tick_params(axis='y', labelcolor='blue')

# Create a second axis sharing the same x-axis
ax2 = ax1.twinx()

# Plot the Unemployment Rate data
ax2.plot(ir_df['TimeIndex'], gdp_df['GDP Growth'], color='red', label='GDP Growth Rate')
ax2.set_ylabel('GDP Growth Rate', color='red')
ax2.tick_params(axis='y', labelcolor='red')

x_ticks = np.arange(0, 290, 24)
ax1.set_xticks(x_ticks)

plt.title('Time Series Plot of ZHVI and GDP Growth Rate Over Time')

# legend
ax1.legend(loc='upper left')
ax2.legend(loc='upper right')

plt.show()

"""OLS Model"""

# Split data into training and test
train = full_df[(full_df['Year'] < 2014) | ((full_df['Year'] == 2013) & (full_df['Month'] <= 12))]
test = full_df[(full_df['Year'] > 2013) | ((full_df['Year'] == 2014) & (full_df['Month'] >= 1))]

# Define features and target
X_train = train[['Year', 'Month', 'TimeIndex', 'Unemployment Rate', 'CPI', 'Interest Rate', 'GDP Growth']]
y_train = train['ZHVI']

# Prediction test
X_test = test[['Year', 'Month', 'TimeIndex','Unemployment Rate', 'CPI','Interest Rate', 'GDP Growth']]

# add polynomial features and scale
scaler = StandardScaler()
poly = PolynomialFeatures(degree=2)

X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

X_train_scaled = scaler.fit_transform(X_train_poly)
X_test_scaled = scaler.transform(X_test_poly)

# add constant
X_train_scaled = sm.add_constant(X_train_scaled)
X_test_scaled = sm.add_constant(X_test_scaled)

# Fit OLS model
model = sm.OLS(y_train, X_train_scaled)
results = model.fit()

predictions = results.predict(X_test_scaled)
test['Predicted_ZHVI'] = predictions

y_test = test['ZHVI']
y_pred = test['Predicted_ZHVI']
OLS_pred = test['Predicted_ZHVI']

# model evaluation
rmse = math.sqrt(mean_squared_error(y_test, y_pred))
print(f"OLS Root Mean Squared Error (RMSE): {rmse}")
mape = mean_absolute_percentage_error(y_test, y_pred)
print("OLS Mean Absolute Percentage Error(MAPE):", mape)
MAE = mean_absolute_error(y_test, y_pred)
print("OLS Mean Absolute Error(MAE):", MAE)
r2 = r2_score(y_pred,y_test)
print(f"OLS R-squared(R^2): {r2}")

# Plot truth vs prediction
plt.figure(figsize=(18, 6))
plt.plot(test['Year-Month'], test['ZHVI'], color='red', label='Truth (ZHVI)')
plt.plot(test['Year-Month'], test['Predicted_ZHVI'], color='blue', label='Predicted ZHVI')
plt.xlabel('Year')
plt.ylabel('Price')
x_ticks = np.arange(0, 80, 6)
plt.xticks(x_ticks)
plt.title('Time Series Plot: Truth vs OLS Predicted ZHVI')
plt.legend(loc='upper left')
plt.show()

# Get feature names
feature_names = ['const'] + list(poly.get_feature_names_out(X_train.columns))

# Create dataframe to store coefficients and feature names
coefficients_df = pd.DataFrame({
    'Feature': feature_names,
    'Coefficient': results.params
})

# sort features by coeff magnitude
coefficients_df['Absolute_Coefficient'] = np.abs(coefficients_df['Coefficient'])
coefficients_df = coefficients_df.sort_values(by='Absolute_Coefficient', ascending=False)

print("Sorted Top 10 OLS Regression Coefficients:")
print(coefficients_df[0:10])

# plot coeff
plt.figure(figsize=(10, 6))
plt.barh(coefficients_df['Feature'][:10], coefficients_df['Absolute_Coefficient'][:10], color='skyblue')
plt.xlabel('Absolute Coefficient Value')
plt.ylabel('Feature')
plt.title('Top 10 Most Important Features (OLS Regression)')
plt.gca().invert_yaxis()
plt.show()

"""Lasso Regression Model"""

# Split data into training and test
train = full_df[(full_df['Year'] < 2014) | ((full_df['Year'] == 2013) & (full_df['Month'] <= 12))]
test = full_df[(full_df['Year'] > 2013) | ((full_df['Year'] == 2014) & (full_df['Month'] >= 1))]

# Define features and target
X_train = train[['Year', 'Month', 'TimeIndex', 'Unemployment Rate', 'CPI','Interest Rate', 'GDP Growth']]
y_train = train['ZHVI']

# Prepare test data for prediction
X_test = test[['Year', 'Month', 'TimeIndex', 'Unemployment Rate', 'CPI','Interest Rate', 'GDP Growth']]

# add polynomial features and scale
scaler = StandardScaler()
poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

X_train_scaled = scaler.fit_transform(X_train_poly)
X_test_scaled = scaler.transform(X_test_poly)

# Fit Lasso regression model
alphas = [0.001,0.005,0.01, 0.05, 0.1, 0.5, 1, 2, 3, 5, 10,25,50,75,100,150]
results = []
lowest_alpha = alphas[0]
lowest_mape = float('inf')

for alpha in alphas:
  lasso_model = Lasso(alpha=alpha)
  lasso_model.fit(X_train_scaled, y_train)

  # Predict
  predictions = lasso_model.predict(X_test_scaled)
  test['Predicted_ZHVI'] = predictions

  # Model evaluation
  y_test = test['ZHVI']
  y_pred = test['Predicted_ZHVI']
  lasso_pred = test['Predicted_ZHVI']

  mape = mean_absolute_percentage_error(y_test, y_pred)
  results.append(mape)
  if mape < lowest_mape:
    lowest_mape = mape
    lowest_alpha = alpha

print("Lowest MAPE:", lowest_mape)
print("Lowest Alpha:", lowest_alpha)

# Plot hyperparameter tuning
plt.plot(alphas, results, marker='o')
plt.xscale('log')

plt.xlabel('Alpha (log scale)')
plt.ylabel('MAPE')
plt.title('Lasso Regression Alpha Tuning - MAPE vs Alpha (Logarithmic X-axis)')

plt.show()

alpha = lowest_alpha

lasso_model = Lasso(alpha=alpha)
lasso_model.fit(X_train_scaled, y_train)

# Predict
predictions = lasso_model.predict(X_test_scaled)
test['Predicted_ZHVI'] = predictions

# Model evaluation
y_test = test['ZHVI']
y_pred = test['Predicted_ZHVI']
lasso_pred = test['Predicted_ZHVI']

lasso_rmse = math.sqrt(mean_squared_error(y_test, y_pred))
print(f"\n\nLasso Root Mean Squared Error (RMSE): {lasso_rmse}")
lasso_mape = mean_absolute_percentage_error(y_test, y_pred)
print("Lasso Mean Absolute Percentage Error (MAPE):", lasso_mape)
lasso_MAE = mean_absolute_error(y_test, y_pred)
print("Mean Absolute Error (MAE):", lasso_MAE)
lasso_r2 = r2_score(y_pred,y_test)
print(f"R-squared(R^2): {lasso_r2}")

# Plot truth vs prediction
plt.figure(figsize=(18, 6))
plt.plot(test['Year-Month'], test['ZHVI'], color='red', label='Truth (ZHVI)')
plt.plot(test['Year-Month'], test['Predicted_ZHVI'], color='blue', label='Predicted ZHVI')
plt.xlabel('Date')
plt.ylabel('ZHVI')
x_ticks = np.arange(0, 80, 6)
plt.xticks(x_ticks)
plt.title('Time Series Plot: Truth vs Lasso Regression Predicted ZHVI')
plt.legend(loc='upper left')
plt.show()

# Get feature names
feature_names = poly.get_feature_names_out(X_train.columns)

# Create dataframe to store coefficients and feature names
coefficients_df = pd.DataFrame({
    'Feature': feature_names,
    'Coefficient': lasso_model.coef_
})

# sort features by coeff magnitude
coefficients_df['Absolute_Coefficient'] = np.abs(coefficients_df['Coefficient'])
coefficients_df = coefficients_df.sort_values(by='Absolute_Coefficient', ascending=False)

print("Sorted Top 10 Lasso Regression Coefficients:")
print(coefficients_df[0:10])

# plot coeff
plt.figure(figsize=(10, 6))
plt.barh(coefficients_df['Feature'][:10], coefficients_df['Absolute_Coefficient'][:10], color='skyblue')
plt.xlabel('Absolute Coefficient Value')
plt.ylabel('Feature')
plt.title('Top 10 Most Important Features (Lasso Regression)')
plt.gca().invert_yaxis()
plt.show()

"""Ridge Regression Model"""

# Split data into training and test
train = full_df[(full_df['Year'] < 2014) | ((full_df['Year'] == 2013) & (full_df['Month'] <= 12))]
test = full_df[(full_df['Year'] > 2013) | ((full_df['Year'] == 2014) & (full_df['Month'] >= 1))]

# Define features and target
X_train = train[['Year', 'Month', 'TimeIndex', 'Unemployment Rate', 'CPI','Interest Rate', 'GDP Growth']]
y_train = train['ZHVI']

X_test = test[['Year', 'Month', 'TimeIndex', 'Unemployment Rate', 'CPI','Interest Rate', 'GDP Growth']]

# add polynomial features and scale
scaler = StandardScaler()
poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

X_train_scaled = scaler.fit_transform(X_train_poly)
X_test_scaled = scaler.transform(X_test_poly)

# Fit Ridge regression model
alphas = [0.001,0.005,0.01, 0.05, 0.075, 0.1, 0.25, 0.35, 0.5, 1, 2, 3, 5, 10]

lowest_alpha = alphas[0]
lowest_mape = float('inf')
results = []
for alpha in alphas:
  ridge_model = Ridge(alpha=alpha)
  ridge_model.fit(X_train_scaled, y_train)

  # Predict
  predictions = ridge_model.predict(X_test_scaled)
  test['Predicted_ZHVI'] = predictions

  # Model evaluation
  y_test = test['ZHVI']
  y_pred = test['Predicted_ZHVI']
  ridge_pred = test['Predicted_ZHVI']

  mape = mean_absolute_percentage_error(y_test, y_pred)
  results.append(mape)
  if mape < lowest_mape:
    lowest_mape = mape
    lowest_alpha = alpha

print("Lowest MAPE:", lowest_mape)
print("Lowest Alpha:", lowest_alpha)

# Plot hyperparameter tuning
plt.plot(alphas, results, marker='o')
plt.xscale('log')

plt.xlabel('Alpha (log scale)')
plt.ylabel('MAPE')
plt.title('Ridge Regression Alpha Tuning - MAPE vs Alpha (Logarithmic X-axis)')

plt.show()

alpha = lowest_alpha
ridge_model = Ridge(alpha=alpha)
ridge_model.fit(X_train_scaled, y_train)

# Predict
predictions = ridge_model.predict(X_test_scaled)
test['Predicted_ZHVI'] = predictions

# Model evaluation
y_test = test['ZHVI']
y_pred = test['Predicted_ZHVI']
ridge_pred = test['Predicted_ZHVI']

ridge_rmse = math.sqrt(mean_squared_error(y_test, y_pred))
print(f"\n\nRR Root Mean Squared Error (RMSE): {ridge_rmse}")
ridge_mape = mean_absolute_percentage_error(y_test, y_pred)
print("RR Mean Absolute Percentage Error(MAPE):", ridge_mape)
ridge_MAE = mean_absolute_error(y_test, y_pred)
print("RR Mean Absolute Error(MAE):", ridge_MAE)
ridge_r2 = r2_score(y_pred,y_test)
print(f"R-squared(R^2): {ridge_r2}")

# Plot truth vs prediction
plt.figure(figsize=(18, 6))
plt.plot(test['Year-Month'], test['ZHVI'], color='red', label='Truth (ZHVI)')
plt.plot(test['Year-Month'], test['Predicted_ZHVI'], color='blue', label='Predicted ZHVI')
plt.xlabel('Year')
plt.ylabel('ZHVI')
x_ticks = np.arange(0, 80, 6)
plt.xticks(x_ticks)
plt.title('Time Series Plot: Truth vs Ridge Regression Predicted ZHVI')
plt.legend(loc='upper left')
plt.show()

# Get feature names
feature_names = poly.get_feature_names_out(X_train.columns)

# Create dataframe to store coefficients and feature names
coefficients_df = pd.DataFrame({
    'Feature': feature_names,
    'Coefficient': ridge_model.coef_
})

# sort features by coeff magnitude
coefficients_df['Absolute_Coefficient'] = np.abs(coefficients_df['Coefficient'])
coefficients_df = coefficients_df.sort_values(by='Absolute_Coefficient', ascending=False)

print("Sorted Top 10 Ridge Regression Coefficients:")
print(coefficients_df[0:10])

# plot coeff
plt.figure(figsize=(10, 6))
plt.barh(coefficients_df['Feature'][:10], coefficients_df['Absolute_Coefficient'][:10], color='skyblue')
plt.xlabel('Absolute Coefficient Value')
plt.ylabel('Feature')
plt.title('Top 10 Most Important Features (Ridge Regression)')
plt.gca().invert_yaxis()
plt.show()

plt.figure(figsize=(18, 6))
plt.plot(test['Year-Month'], test['ZHVI'], color='black', label='True ZHVI')
plt.plot(test['Year-Month'], OLS_pred, color='blue', label='OLS Predicted ZHVI')
plt.plot(test['Year-Month'], lasso_pred, color='green', label='Lasso Predicted ZHVI')
plt.plot(test['Year-Month'], ridge_pred, color='red', label='Ridge Predicted ZHVI')

plt.xlabel('Date')
plt.ylabel('ZHVI')
x_ticks = np.arange(0, 80, 6)
plt.xticks(x_ticks)
plt.title('Time Series Plot of OLS, Ridge, and Lasso Regression: True vs Predicted ZHVI')

plt.legend(loc='upper left')

plt.show()

"""milestone 2"""

!pip install keras-tuner
!pip install -q streamlit
!npm install localtunnel

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Activation
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit
from sklearn.linear_model import LinearRegression
from tabulate import tabulate

import tensorflow as tf
import keras_tuner as kt
import math
import matplotlib.pyplot as plt
import numpy as np
import random
import xgboost as xgb
import statsmodels.api as sm
import joblib
import xgboost as xgb

clear_output()

"""DNN Model"""

# Hyperparameter tuning

random.seed(158)

# Preprocess data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Define the model building function for Keras Tuner
def build_model(hp):

    model = Sequential()

    # Tune the number of units in the first Dense layer
    model.add(Dense(
        units=hp.Int('units_1', min_value=64, max_value=256, step=64),
        activation='relu',
        input_shape=(X_train_scaled.shape[1],)
    ))
    model.add(Dropout(
        rate=hp.Float('dropout_1', min_value=0.0, max_value=0.5, step=0.1)
    ))

    # Tune the number of hidden layers (1-3)
    for i in range(hp.Int('num_layers', 1, 3)):
        model.add(Dense(
            units=hp.Int(f'units_{i+2}', min_value=32, max_value=128, step=32),
            activation='relu')
        )
        model.add(Dropout(
            rate=hp.Float(f'dropout_{i+2}', min_value=0.0, max_value=0.5, step=0.1)
        ))

    model.add(Dense(1))

    # Tune the learning rate
    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])

    optimizer = Adam(learning_rate=learning_rate)
    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])

    return model

# Set up the tuner
tuner = kt.RandomSearch(
    build_model,
    objective='val_loss',
    max_trials=20,
    executions_per_trial=2,
    directory='keras_tuner',
    project_name='zhvi_prediction'
)

# Early stopping callback
early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True
)

# Perform hyperparameter search
tuner.search(
    X_train_scaled, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=[early_stopping],
    verbose=1
)

# Get the best hyperparameters
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]

print(f"""
The hyperparameter search is complete. The optimal hyperparameters are:
- Units in first layer: {best_hps.get('units_1')}
- Number of hidden layers: {best_hps.get('num_layers')}
- Learning rate: {best_hps.get('learning_rate')}
- Dropout rate (first layer): {best_hps.get('dropout_1')}
""")

# Build the model with the best hyperparameters
best_model = tuner.hypermodel.build(best_hps)

# Train the best model
history = best_model.fit(
    X_train_scaled, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    callbacks=[early_stopping],
    verbose=1
)

# Plot training history
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss (MSE)')
plt.title('Neural Network Training History')
plt.legend()
plt.show()

# Predictions
nn_predictions = best_model.predict(X_test_scaled).flatten()
test['NN_Predicted_ZHVI'] = nn_predictions

# Model evaluation
nn_rmse = math.sqrt(mean_squared_error(y_test, nn_predictions))
print(f"Neural Network Root Mean Squared Error (RMSE): {nn_rmse}")
nn_mape = mean_absolute_percentage_error(y_test, nn_predictions)
print("Neural Network Mean Absolute Percentage Error (MAPE):", nn_mape)
nn_mae = mean_absolute_error(y_test, nn_predictions)
print("Neural Network Mean Absolute Error (MAE):", nn_mae)
nn_r2 = r2_score(y_test, nn_predictions)
print(f"Neural Network R-squared (R^2): {nn_r2}")

# Plot truth vs prediction
plt.figure(figsize=(18, 6))
plt.plot(test['Year-Month'], test['ZHVI'], color='red', label='Truth (ZHVI)')
plt.plot(test['Year-Month'], test['NN_Predicted_ZHVI'], color='purple', label='Neural Network Predicted ZHVI')
plt.xlabel('Date')
plt.ylabel('ZHVI')
x_ticks = np.arange(0, 80, 6)
plt.xticks(x_ticks)
plt.title('Time Series Plot: Truth vs Neural Network Predicted ZHVI (Optimized)')
plt.legend(loc='upper left')
plt.show()

# Split data into training and test
train = full_df[(full_df['Year'] < 2014) | ((full_df['Year'] == 2013) & (full_df['Month'] <= 12))]
test = full_df[(full_df['Year'] > 2013) | ((full_df['Year'] == 2014) & (full_df['Month'] >= 1))]

# Define features and target
X_train = train[['Year', 'Month', 'TimeIndex', 'Unemployment Rate', 'CPI','Interest Rate', 'GDP Growth']]
y_train = train['ZHVI']

# Prepare test data for prediction
X_test = test[['Year', 'Month', 'TimeIndex', 'Unemployment Rate', 'CPI','Interest Rate', 'GDP Growth']]

# set seed for easy reproducibility of different configurations
random.seed(158)

# preprocess data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Build neural network
model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(1)
])

optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])

# Train the model
history = model.fit(
    X_train_scaled, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    verbose=1
)

clear_output()

# Predictions
nn_predictions = model.predict(X_test_scaled).flatten()
test['NN_Predicted_ZHVI'] = nn_predictions

# Model evaluation
nn_rmse = math.sqrt(mean_squared_error(y_test, nn_predictions))
print(f"Neural Network Root Mean Squared Error (RMSE): {nn_rmse}")
nn_mape = mean_absolute_percentage_error(y_test, nn_predictions)
print("Neural Network Mean Absolute Percentage Error (MAPE):", nn_mape)
nn_mae = mean_absolute_error(y_test, nn_predictions)
print("Neural Network Mean Absolute Error (MAE):", nn_mae)
nn_r2 = r2_score(y_test, nn_predictions)
print(f"Neural Network R-squared (R^2): {nn_r2}")

# Plot truth vs prediction
plt.figure(figsize=(18, 6))
plt.plot(test['Year-Month'], test['ZHVI'], color='red', label='Truth (ZHVI)')
plt.plot(test['Year-Month'], test['NN_Predicted_ZHVI'], color='purple', label='Neural Network Predicted ZHVI')
plt.xlabel('Date')
plt.ylabel('ZHVI')
x_ticks = np.arange(0, 80, 6)
plt.xticks(x_ticks)
plt.title('Time Series Plot: Truth vs Neural Network Predicted ZHVI')
plt.legend(loc='upper left')
plt.show()

"""Random Forest Model"""

# Split data into training and test (same as before)
train = full_df[(full_df['Year'] < 2014) | ((full_df['Year'] == 2013) & (full_df['Month'] <= 12))]
test = full_df[(full_df['Year'] > 2013) | ((full_df['Year'] == 2014) & (full_df['Month'] >= 1))]

# Define features and target
X_train = train[['Year', 'Month', 'TimeIndex', 'Unemployment Rate', 'CPI', 'Interest Rate', 'GDP Growth']]
y_train = train['ZHVI']
X_test = test[['Year', 'Month', 'TimeIndex', 'Unemployment Rate', 'CPI', 'Interest Rate', 'GDP Growth']]
y_test = test['ZHVI']

# add polynomial features and scale
scaler = StandardScaler()
poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

# Get feature names from polynomial features
feature_names = poly.get_feature_names_out(input_features=X_train.columns)

X_train_scaled = scaler.fit_transform(X_train_poly)
X_test_scaled = scaler.transform(X_test_poly)

# Hyperparameter tuning with GridSearchCV
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

rf = RandomForestRegressor(random_state=42)
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,
                          cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')
grid_search.fit(X_train_scaled, y_train)

# Best model
best_rf = grid_search.best_estimator_
print(f"Best Random Forest parameters: {grid_search.best_params_}")

# Predictions
rf_predictions = best_rf.predict(X_test_scaled)
test['RF_Predicted_ZHVI'] = rf_predictions

# Model evaluation
rf_rmse = math.sqrt(mean_squared_error(y_test, rf_predictions))
print(f"Random Forest Root Mean Squared Error (RMSE): {rf_rmse}")
rf_mape = mean_absolute_percentage_error(y_test, rf_predictions)
print("Random Forest Mean Absolute Percentage Error (MAPE):", rf_mape)
rf_mae = mean_absolute_error(y_test, rf_predictions)
print("Random Forest Mean Absolute Error (MAE):", rf_mae)
rf_r2 = r2_score(y_test, rf_predictions)
print(f"Random Forest R-squared (R^2): {rf_r2}")

# Feature importance
feature_importance = pd.DataFrame({
    'Feature': feature_names,
    'Importance': best_rf.feature_importances_
}).sort_values('Importance', ascending=False)

print("\nRandom Forest Feature Importance:")
print(feature_importance)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='skyblue')
plt.xlabel('Importance Score')
plt.ylabel('Feature')
plt.title('Random Forest Feature Importance')
plt.gca().invert_yaxis()
plt.show()

# Plot truth vs prediction
plt.figure(figsize=(18, 6))
plt.plot(test['Year-Month'], test['ZHVI'], color='red', label='Truth (ZHVI)')
plt.plot(test['Year-Month'], test['RF_Predicted_ZHVI'], color='green', label='Random Forest Predicted ZHVI')
plt.xlabel('Date')
plt.ylabel('ZHVI')
x_ticks = np.arange(0, 80, 6)
plt.xticks(x_ticks)
plt.title('Time Series Plot: Truth vs Random Forest Predicted ZHVI')
plt.legend(loc='upper left')
plt.show()

"""XGBoost Model"""

# Split data into training and test (same as before)
train = full_df[(full_df['Year'] < 2014) | ((full_df['Year'] == 2013) & (full_df['Month'] <= 12))]
test = full_df[(full_df['Year'] > 2013) | ((full_df['Year'] == 2014) & (full_df['Month'] >= 1))]

# Define features and target
X_train = train[['Year', 'Month', 'TimeIndex', 'Unemployment Rate', 'CPI', 'Interest Rate', 'GDP Growth']]
y_train = train['ZHVI']
X_test = test[['Year', 'Month', 'TimeIndex', 'Unemployment Rate', 'CPI', 'Interest Rate', 'GDP Growth']]
y_test = test['ZHVI']

# Feature Engineering Functions
def create_features(df, target_col='ZHVI'):
    # Create lag features
    for lag in [1, 2, 3, 6, 12]:  # Multiple time horizons
        df[f'{target_col}_lag_{lag}'] = df[target_col].shift(lag)

    # Create rolling statistics
    for window in [3, 6, 12]:
        df[f'{target_col}_rolling_avg_{window}'] = df[target_col].rolling(window).mean()
        df[f'{target_col}_rolling_std_{window}'] = df[target_col].rolling(window).std()

    # Month/year indicators
    df['month_sin'] = np.sin(2 * np.pi * df['Month']/12)
    df['month_cos'] = np.cos(2 * np.pi * df['Month']/12)

    return df

# Data Preparation
train = create_features(train.copy())
test = create_features(test.copy())

# Define features
base_features = ['Year', 'Month', 'TimeIndex', 'Unemployment Rate',
                'CPI', 'Interest Rate', 'GDP Growth', 'month_sin', 'month_cos']
lag_features = [col for col in train.columns if 'lag_' in col or 'rolling_' in col]
features = base_features + lag_features

# Handle missing values from lag features
X_train = train[features].dropna()
y_train = train.loc[X_train.index, 'ZHVI']
X_test = test[features].dropna()
y_test = test.loc[X_test.index, 'ZHVI']

# add polynomial features and scale
scaler = StandardScaler()
poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)
X_train_scaled = scaler.fit_transform(X_train_poly)
X_test_scaled = scaler.transform(X_test_poly)

# XGBoost with Native API for MAPE Optimization
def xgboost_mape_train(X_train, y_train, X_test, y_test, params):
    # Convert to DMatrix format
    dtrain = xgb.DMatrix(X_train, label=y_train)
    dtest = xgb.DMatrix(X_test, label=y_test)

    # Custom MAPE evaluation metric
    def mape_eval(preds, dmatrix):
        labels = dmatrix.get_label()
        return 'mape', np.mean(np.abs((labels - preds) / (labels + 1e-6))) * 100

    # Train model
    model = xgb.train(
        params,
        dtrain,
        num_boost_round=1000,
        evals=[(dtrain, 'train'), (dtest, 'test')],
        early_stopping_rounds=50,
        feval=mape_eval,
        verbose_eval=50
    )
    return model

# Parameter Tuning with scikit-learn API
param_grid = {
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.05, 0.1],
    'subsample': [0.8, 0.9, 1.0],
    'colsample_bytree': [0.8, 0.9, 1.0],
    'gamma': [0, 0.1, 0.2],
    'min_child_weight': [1, 3, 5]
}

xgb_sklearn = xgb.XGBRegressor(
    objective='reg:squarederror',
    n_estimators=100,
    random_state=42,
    n_jobs=-1
)

tscv = TimeSeriesSplit(n_splits=3)
search = RandomizedSearchCV(
    estimator=xgb_sklearn,
    param_distributions=param_grid,
    n_iter=20,
    cv=tscv,
    scoring='neg_mean_absolute_percentage_error',
    verbose=1,
    n_jobs=-1,
    random_state=42
)

search.fit(X_train_scaled, y_train)
best_params = search.best_params_

# Final Model Training with MAPE Focus
final_params = {
    **best_params,
    'objective': 'reg:squarederror',
    'seed': 158
}

# Train with native API
xgb_model = xgboost_mape_train(
    X_train_scaled, y_train,
    X_test_scaled, y_test,
    final_params
)

# Evaluation
xgb_predictions = xgb_model.predict(xgb.DMatrix(X_test_scaled))
test.loc[X_test.index, 'XGBoost_Predicted_ZHVI'] = xgb_predictions

xgb_rmse = math.sqrt(mean_squared_error(y_test, xgb_predictions))
xgb_mape = mean_absolute_percentage_error(y_test, xgb_predictions)
xgb_mae = mean_absolute_error(y_test, xgb_predictions)
xgb_r2 = r2_score(y_test, xgb_predictions)

metrics = {
    'RMSE': xgb_rmse,
    'MAPE': xgb_mape,
    'MAE': xgb_mae,
    'R2': xgb_r2
}

print("\nModel Performance:")
for name, value in metrics.items():
    print(f"{name}: {value:.4f}")

# Plot truth vs prediction
plt.figure(figsize=(18, 6))
plt.plot(test['Year-Month'], test['ZHVI'], color='red', label='Truth (ZHVI)')
plt.plot(test['Year-Month'], test['XGBoost_Predicted_ZHVI'], color='darkgreen', label='XGBoost Predicted ZHVI')
plt.xlabel('Date')
plt.ylabel('ZHVI')
x_ticks = np.arange(0, 80, 6)
plt.xticks(x_ticks)
plt.title('Time Series Plot: Truth vs XGBoost Predicted ZHVI')
plt.legend(loc='upper left')
plt.show()

"""Comparison of Models"""

# Combined Model Comparison Plot
plt.figure(figsize=(18, 6))
plt.plot(test['Year-Month'], test['ZHVI'], color='black', label='True ZHVI')
plt.plot(test['Year-Month'], OLS_pred, color='pink', label='OLS Predicted ZHVI')
plt.plot(test['Year-Month'], lasso_pred, color='green', label='Lasso Predicted ZHVI')
plt.plot(test['Year-Month'], ridge_pred, color='red', label='Ridge Predicted ZHVI')
plt.plot(test['Year-Month'], nn_predictions, color='purple', label='Neural Network Predicted ZHVI')
plt.plot(test['Year-Month'], rf_predictions, color='orange', label='Random Forest Predicted ZHVI')
plt.plot(test['Year-Month'], test['XGBoost_Predicted_ZHVI'], color='blue', label='XGBoost Predicted ZHVI')


plt.xlabel('Date')
plt.ylabel('ZHVI')
x_ticks = np.arange(0, 80, 6)
plt.xticks(x_ticks)
plt.title('Time Series Plot: True vs All Model Predictions')
plt.legend(loc='upper left')
plt.show()

# Model Performance Comparison Table
model_comparison = pd.DataFrame({
    'Model': ['OLS', 'Lasso', 'Ridge', 'Neural Network', 'Random Forest', 'XGBoost'],
    'RMSE': [rmse, lasso_rmse, ridge_rmse, nn_rmse, rf_rmse, xgb_rmse],
    'MAPE': [mape, lasso_mape, ridge_mape, nn_mape, rf_mape, xgb_mape],
    'MAE': [MAE, lasso_MAE, ridge_MAE, nn_mae, rf_mae, xgb_mae],
    'R2': [r2, lasso_r2, ridge_r2, nn_r2, rf_r2, xgb_r2]
})

print("\nModel Performance Comparison:")
print(model_comparison.sort_values('RMSE'))

"""Ensemble Model"""

# ensemble model
original_features = ['Year', 'Month', 'TimeIndex', 'Unemployment Rate', 'CPI', 'Interest Rate', 'GDP Growth']

# add polynomial features and scaling
poly = PolynomialFeatures(degree=2, include_bias=False)
X_train_poly = poly.fit_transform(X_train[original_features])
X_test_poly = poly.transform(X_test[original_features])

print("Number of polynomial features:", X_train_poly.shape[1])

X_train_poly = np.column_stack([np.ones(X_train_poly.shape[0]), X_train_poly])  # Add bias column
X_test_poly = np.column_stack([np.ones(X_test_poly.shape[0]), X_test_poly])

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_poly)
X_test_scaled = scaler.transform(X_test_poly)


# model dictionary for ensemble
trained_models = {
    'Lasso': lasso_model,
    'Ridge': ridge_model,
    'Random Forest': best_rf,
    'XGBoost': xgb_model
}

# Prediction function
def get_predictions(model, X, model_type):
    if model_type in ['Lasso', 'Ridge', 'Random Forest']:
        if hasattr(model, 'n_features_in_'):
            if X.shape[1] != model.n_features_in_:
                raise ValueError(f"Feature mismatch! Model expects {model.n_features_in_} features but got {X.shape[1]}")

    if model_type == 'XGBoost':
        return model.predict(xgb.DMatrix(X))
    elif model_type == 'Neural Network':
        return model.predict(X).flatten()
    else:
        return model.predict(X)


# Generate predictions
predictions_train = {name: get_predictions(model, X_train_scaled, name)
                    for name, model in trained_models.items()}
predictions_test = {name: get_predictions(model, X_test_scaled, name)
                   for name, model in trained_models.items()}

# Create ensemble DataFrames
ensemble_train = pd.DataFrame(predictions_train)
ensemble_test = pd.DataFrame(predictions_test)
ensemble_train['True_ZHVI'] = y_train.values
ensemble_test['True_ZHVI'] = y_test.values

def evaluate_predictions(name, y_true, y_pred):
    return {
        'Model': name,
        'MAE': mean_absolute_error(y_true, y_pred),
        'RMSE': math.sqrt(mean_squared_error(y_true, y_pred)),
        'MAPE': mean_absolute_percentage_error(y_true, y_pred) * 100,
        'R2': r2_score(y_true, y_pred)
    }

# Ensemble Comparison
print("\n Ensemble Comparison")

# Evaluate ensemble methods
ensemble_results = []

# Simple Average Ensemble
simple_avg = ensemble_test.drop(columns=['True_ZHVI']).mean(axis=1)
ensemble_results.append(evaluate_predictions(
    'Simple Average', y_test, simple_avg
))

# Weighted Average Ensemble (weighted by inverse MAE)
model_weights = {m: 1/mean_absolute_error(y_test, ensemble_test[m])
                for m in trained_models}
total_weight = sum(model_weights.values())
weighted_avg = sum(ensemble_test[m]*(w/total_weight) for m,w in model_weights.items())
ensemble_results.append(evaluate_predictions(
    'Weighted Average', y_test, weighted_avg
))

# Stacking Ensemble
predictions_train = {name: get_predictions(model, X_train_scaled, name)
                    for name, model in trained_models.items()}

meta_model = LinearRegression()
meta_model.fit(ensemble_train.drop(columns=['True_ZHVI']), ensemble_train['True_ZHVI'])
stacking_pred = meta_model.predict(ensemble_test.drop(columns=['True_ZHVI']))
ensemble_results.append(evaluate_predictions(
    'Stacking Ensemble', y_test, stacking_pred
))

# Create comparison DataFrame
ensemble_comparison = pd.DataFrame(ensemble_results)
ensemble_comparison.sort_values('MAPE', inplace=True)

# Format for display
display_df = ensemble_comparison.copy()
for col in ['MAE', 'RMSE']:
    display_df[col] = display_df[col].apply(lambda x: f"{x:,.2f}")
display_df['MAPE'] = display_df['MAPE'].apply(lambda x: f"{x:.2f}%")
display_df['R2'] = display_df['R2'].apply(lambda x: f"{x:.4f}")

print("\nEnsemble Methods Performance (Sorted by MAPE):")
print(tabulate(display_df[['Model', 'MAE', 'RMSE', 'MAPE', 'R2']],
               headers='keys', tablefmt='psql', showindex=False))

# Best ensemble method
best_ensemble = ensemble_comparison.iloc[0]
print(f"\nBest Performing Ensemble Method: {best_ensemble['Model']}")
print(f"- MAE: {best_ensemble['MAE']:,.2f}")
print(f"- RMSE: {best_ensemble['RMSE']:,.2f}")
print(f"- MAPE: {best_ensemble['MAPE']:.2f}%")
print(f"- R2: {best_ensemble['R2']:.4f}")

# Save the complete ensemble model
ensemble_package = {
            'base_models': {name: model for name, model in trained_models.items() if name in predictions_train},
            'meta_model': meta_model,
            'poly': poly,
            'scaler': scaler,
            'feature_names': original_features,
            'get_predictions': get_predictions
        }

joblib.dump(ensemble_package, 'final_zhvi_ensemble_model.pkl')

"""Model Comparison"""

# Create and display comparison
comparison_df = pd.DataFrame(ensemble_comparison)
comparison_df.loc[3] = ['OLS', MAE, rmse, mape*100, r2]
comparison_df.loc[4] = ['Ridge', ridge_MAE, ridge_rmse, ridge_mape*100, ridge_r2]
comparison_df.loc[5] = ['Lasso', lasso_MAE, lasso_rmse, lasso_mape*100, lasso_r2]
comparison_df.loc[6] = ['Random Forest', rf_mae, rf_rmse, rf_mape*100, rf_r2]
comparison_df.loc[7] = ['Neural Network', nn_mae, nn_rmse, nn_mape*100, nn_r2]
comparison_df.loc[8] = ['XGBoost', xgb_mae, xgb_rmse, xgb_mape*100, xgb_r2]

comparison_df.sort_values('MAPE', inplace=True)

# Format for display
display_df = comparison_df.copy()
for col in ['MAE', 'RMSE']:
    display_df[col] = display_df[col].apply(lambda x: f"{x:,.2f}")
display_df['MAPE'] = display_df['MAPE'].apply(lambda x: f"{x:.2f}%")
display_df['R2'] = display_df['R2'].apply(lambda x: f"{x:.4f}")

print("\nModel Performance Comparison (Sorted by MAPE):")
print(tabulate(display_df[['Model', 'MAE', 'RMSE', 'MAPE', 'R2']],
               headers='keys', tablefmt='psql', showindex=False))

# Visualization
metrics = ['MAE', 'RMSE', 'MAPE', 'R2']
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('Model Performance Comparison', y=1.02)

for ax, metric in zip(axes.flatten(), metrics):
    if metric == 'MAPE':
        comparison_df.plot.barh(x='Model', y=metric, ax=ax, legend=False)
        ax.set_xlabel('MAPE (%)')
    elif metric == 'R2':
        comparison_df.plot.barh(x='Model', y=metric, ax=ax, legend=False)
        ax.set_xlabel('R² Score')
    else:
        comparison_df.plot.barh(x='Model', y=metric, ax=ax, legend=False)
        ax.set_xlabel(metric)

    ax.invert_yaxis()
    ax.grid(True, linestyle='--', alpha=0.6)

plt.tight_layout()
plt.show()

# Best model summary
best_model = comparison_df.iloc[0]
print(f"\nBest Performing Model: {best_model['Model']}")
print(f"- MAE: {best_model['MAE']:,.2f}")
print(f"- RMSE: {best_model['RMSE']:,.2f}")
print(f"- MAPE: {best_model['MAPE']:.2f}%")
print(f"- R2: {best_model['R2']:.4f}")

valid_test_indices = ensemble_test.index + 12
valid_dates = test['Year-Month'].iloc[valid_test_indices]

# Set up the plot
plt.figure(figsize=(20, 8))

# Plot
plt.plot(valid_dates, test['ZHVI'].iloc[valid_test_indices], color='black', linewidth=3, label='True ZHVI', marker='o', markersize=5)
plt.plot(valid_dates, OLS_pred.iloc[valid_test_indices], color='darkblue', linestyle='-', label='OLS')
plt.plot(valid_dates, lasso_pred.iloc[valid_test_indices], color='green', linestyle='--', label='Lasso')
plt.plot(valid_dates, ridge_pred.iloc[valid_test_indices], color='red', linestyle='--', label='Ridge')
plt.plot(valid_dates, nn_predictions[valid_test_indices], color='purple', linestyle='-.', label='Neural Network')
plt.plot(valid_dates, rf_predictions[valid_test_indices], color='orange', linestyle=':', label='Random Forest')
plt.plot(valid_dates, test['XGBoost_Predicted_ZHVI'].iloc[valid_test_indices], color='blue', linestyle=':', label='XGBoost')
plt.plot(valid_dates, simple_avg, color='cyan', linewidth=2, linestyle='-', label='Simple Average Ensemble')
plt.plot(valid_dates, weighted_avg, color='magenta', linewidth=2, linestyle='-', label='Weighted Average Ensemble')
plt.plot(valid_dates, stacking_pred, color='lime', linewidth=2, linestyle='-', label='Stacking Ensemble')

# Formatting
plt.xlabel('Date', fontsize=12)
plt.ylabel('ZHVI', fontsize=12)
plt.title('True vs Predicted ZHVI Values\n(All Models + Ensemble Methods Comparison)',
          fontsize=14, pad=20)
x_ticks = np.arange(0, len(valid_dates), 6)
plt.xticks(x_ticks, valid_dates.iloc[x_ticks], rotation=45)

# Add grid and legend
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)

# Add performance metrics annotation
metrics_text = (
    f"Best Model: {best_ensemble['Model']}\n"
    f"MAPE: {best_ensemble['MAPE']:.2f}%\n"
    f"R²: {best_ensemble['R2']:.4f}\n"
    f"RMSE: {best_ensemble['RMSE']:,.2f}"
)
plt.annotate(metrics_text, xy=(0.02, 0.75), xycoords='axes fraction',
            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))

plt.tight_layout()
plt.show()

"""Streamlit App"""

!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com